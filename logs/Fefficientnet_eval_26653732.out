  0%|          | 0/47 [00:00<?, ?it/s]  2%|▏         | 1/47 [00:28<22:04, 28.80s/it]  4%|▍         | 2/47 [00:29<09:10, 12.23s/it]  6%|▋         | 3/47 [00:30<05:04,  6.93s/it]  9%|▊         | 4/47 [00:30<03:11,  4.44s/it] 11%|█         | 5/47 [00:31<02:08,  3.07s/it] 11%|█         | 5/47 [00:43<06:04,  8.68s/it]
Traceback (most recent call last):
  File "/gscratch/stf/lbc800/fashion-app/eval_fefficient.py", line 122, in <module>
    per_class_ap, macro_ap = eval_fefficient(get_model(path = "weights/Fefficientnet_pt2.pth"), val_loader, device)
  File "/gscratch/stf/lbc800/fashion-app/eval_fefficient.py", line 85, in eval_fefficient
    map_metric.update(outputs, labels)
  File "/usr/local/lib/python3.10/dist-packages/torchmetrics/metric.py", line 559, in wrapped_func
    raise err
  File "/usr/local/lib/python3.10/dist-packages/torchmetrics/metric.py", line 549, in wrapped_func
    update(*args, **kwargs)
  File "/usr/local/lib/python3.10/dist-packages/torchmetrics/classification/precision_recall_curve.py", line 562, in update
    _multilabel_precision_recall_curve_tensor_validation(preds, target, self.num_labels, self.ignore_index)
  File "/usr/local/lib/python3.10/dist-packages/torchmetrics/functional/classification/precision_recall_curve.py", line 737, in _multilabel_precision_recall_curve_tensor_validation
    _binary_precision_recall_curve_tensor_validation(preds, target, ignore_index)
  File "/usr/local/lib/python3.10/dist-packages/torchmetrics/functional/classification/precision_recall_curve.py", line 158, in _binary_precision_recall_curve_tensor_validation
    raise RuntimeError(
RuntimeError: Detected the following values in `target`: tensor([0, 1, 2], device='cuda:0') but expected only the following values [0, 1].
